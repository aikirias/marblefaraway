# ğŸ§ª Tests del Sistema APE Unificado

Este directorio contiene la suite completa de tests para el sistema APE (Automatic Project Estimator), implementando una estrategia pragmÃ¡tica de testing con cobertura completa de casos crÃ­ticos.

## ğŸ“ Estructura de Tests

```
tests/
â”œâ”€â”€ conftest.py                    # ConfiguraciÃ³n pytest + fixtures
â”œâ”€â”€ requirements.txt               # Dependencias de testing
â”œâ”€â”€ unit/                         # Tests de modelos y lÃ³gica pura
â”‚   â”œâ”€â”€ test_models.py            # Tests para Team, Project, Assignment
â”‚   â””â”€â”€ test_business_logic.py    # MÃ©todos de negocio sin dependencias
â”œâ”€â”€ integration/                  # Tests de CRUDs con mocks
â”‚   â”œâ”€â”€ test_cruds.py            # Teams, Projects, Assignments CRUDs
â”‚   â””â”€â”€ test_data_flows.py       # Flujos completos de datos
â””â”€â”€ simulation/                   # Tests crÃ­ticos de simulaciÃ³n
    â”œâ”€â”€ test_simulation_scenarios.py  # Casos crÃ­ticos principales
    â”œâ”€â”€ test_edge_cases.py            # Casos lÃ­mite y errores
    â””â”€â”€ test_priority_handling.py     # Manejo de prioridades
```

## ğŸ¯ Casos CrÃ­ticos Cubiertos

### **Unit Tests**
- âœ… `Team.get_available_devs()` - CÃ¡lculo de capacidad disponible
- âœ… `Assignment.get_hours_needed()` - CÃ¡lculo de horas por tier
- âœ… `Assignment.can_start_on()` - ValidaciÃ³n de fechas
- âœ… `ScheduleResult` - MÃ©todos de consulta y filtrado

### **Integration Tests**
- âœ… CRUDs con mocks de DB (teams, projects, assignments)
- âœ… Operaciones de lectura con JOINs
- âœ… Manejo de errores en operaciones de DB

### **Simulation Tests**
- âœ… **Proyecto simple**: 4 fases secuenciales (Arch â†’ Model â†’ Devs â†’ Dqa)
- âœ… **MÃºltiples proyectos**: VerificaciÃ³n de prioridades
- âœ… **Capacidad limitada**: Sin paralelismo cuando no hay recursos
- âœ… **Dependencias**: Restricciones de ready_to_start_date
- âœ… **Flujo APE completo**: Secuencia real con cÃ¡lculos precisos
- âœ… **Casos lÃ­mite**: Equipos sin capacidad, loops infinitos, datos invÃ¡lidos

## ğŸš€ Ejecutar Tests

### **InstalaciÃ³n de Dependencias**
```bash
pip install -r tests/requirements.txt
```

### **Ejecutar Todos los Tests**
```bash
python run_tests.py
```

### **Ejecutar por CategorÃ­a**
```bash
# Unit tests solamente
python run_tests.py --unit

# Integration tests solamente
python run_tests.py --integration

# Simulation tests solamente
python run_tests.py --simulation

# Tests con cobertura
python run_tests.py --coverage
```

### **Comandos Pytest Directos**
```bash
# Todos los tests con verbose
pytest tests/ -v

# Tests especÃ­ficos
pytest tests/simulation/test_simulation_scenarios.py::TestSimulationScenarios::test_simple_project_sequential_phases -v

# Con cobertura
pytest tests/ --cov=app/modules --cov-report=html --cov-report=term-missing

# Solo tests rÃ¡pidos
pytest tests/ -m "not slow"
```

## ğŸ“Š MÃ©tricas de Cobertura

### **Objetivos de Cobertura**
- **Unit Tests**: 90%+ en modelos y lÃ³gica de negocio
- **Integration Tests**: 80%+ en CRUDs
- **Simulation Tests**: 100% en casos crÃ­ticos

### **Generar Reporte de Cobertura**
```bash
pytest tests/ --cov=app/modules --cov-report=html
# Abre htmlcov/index.html en el navegador
```

## ğŸ§ª Fixtures Disponibles

### **Fixtures BÃ¡sicas**
- `sample_team` - Team de ejemplo con tier_capacities
- `sample_project` - Project de ejemplo con fechas
- `sample_assignment` - Assignment de ejemplo completo
- `mock_connection` - Mock de conexiÃ³n a DB

### **Fixtures APE**
- `ape_teams` - Equipos especializados (Arch, Model, Devs, Dqa)
- `sample_simulation_input` - Input completo para simulaciÃ³n

### **Usar Fixtures en Tests**
```python
def test_my_function(sample_team, sample_assignment):
    # Usar fixtures directamente
    result = my_function(sample_team, sample_assignment)
    assert result is not None
```

## ğŸ”§ ConfiguraciÃ³n de Tests

### **pytest.ini**
```ini
[tool:pytest]
testpaths = tests
addopts = -v --tb=short --strict-markers
markers =
    unit: Unit tests for models and business logic
    integration: Integration tests for CRUDs
    simulation: Simulation tests for critical scenarios
```

### **Markers Disponibles**
```bash
# Ejecutar solo unit tests
pytest -m unit

# Ejecutar solo simulation tests
pytest -m simulation

# Excluir tests lentos
pytest -m "not slow"
```

## ğŸ› Debugging Tests

### **Ejecutar Test Individual con Debug**
```bash
pytest tests/simulation/test_simulation_scenarios.py::TestSimulationScenarios::test_simple_project_sequential_phases -v -s --tb=long
```

### **Usar pdb para Debug**
```python
def test_debug_example():
    import pdb; pdb.set_trace()
    # Tu cÃ³digo de test aquÃ­
```

### **Ver Output Completo**
```bash
pytest tests/ -v -s --tb=short
```

## ğŸ“ˆ Casos de Test CrÃ­ticos

### **1. Dependencias Secuenciales APE**
```python
def test_arch_model_devs_dqa_sequence():
    """Verifica que Arch â†’ Model â†’ Devs â†’ Dqa se ejecutan en orden"""
```

### **2. Manejo de Prioridades**
```python
def test_multiple_projects_priority_handling():
    """Verifica que prioridad 1 se ejecuta antes que prioridad 2"""
```

### **3. Capacidad Limitada**
```python
def test_limited_capacity_no_parallelism():
    """Verifica que no hay paralelismo cuando no hay recursos"""
```

### **4. Restricciones de Fecha**
```python
def test_ready_to_start_date_constraint():
    """Verifica que se respetan las fechas mÃ­nimas de inicio"""
```

## ğŸš¨ Casos LÃ­mite Cubiertos

- âœ… Equipos sin capacidad disponible
- âœ… ProtecciÃ³n contra loops infinitos
- âœ… Listas vacÃ­as de asignaciones
- âœ… Equipos inexistentes
- âœ… Asignaciones con 0 horas
- âœ… Devs fraccionarios (ej: 1.5 devs)
- âœ… Fechas muy antiguas o futuras
- âœ… Tiers inexistentes en capacidades

## ğŸ“ Agregar Nuevos Tests

### **1. Unit Test**
```python
# tests/unit/test_models.py
def test_new_functionality(sample_team):
    """Test nueva funcionalidad"""
    result = sample_team.new_method()
    assert result == expected_value
```

### **2. Integration Test**
```python
# tests/integration/test_cruds.py
def test_new_crud_operation(mock_connection, mocker):
    """Test nueva operaciÃ³n CRUD"""
    # Setup mocks
    # Ejecutar operaciÃ³n
    # Verificar resultados
```

### **3. Simulation Test**
```python
# tests/simulation/test_simulation_scenarios.py
def test_new_scenario():
    """Test nuevo escenario de simulaciÃ³n"""
    # Setup teams, projects, assignments
    # Ejecutar simulaciÃ³n
    # Verificar resultados crÃ­ticos
```

## ğŸ¯ Criterios de AceptaciÃ³n

Para que un test sea considerado exitoso debe:

1. **Pasar consistentemente** en mÃºltiples ejecuciones
2. **Ser independiente** de otros tests
3. **Tener assertions claras** y especÃ­ficas
4. **Cubrir casos edge** relevantes
5. **Usar fixtures apropiadas** para setup
6. **Tener nombres descriptivos** que expliquen quÃ© testea

## ğŸ”„ CI/CD Integration

Los tests estÃ¡n configurados para ejecutarse automÃ¡ticamente en CI/CD:

```yaml
# .github/workflows/tests.yml
- name: Run Unit Tests
  run: pytest tests/unit/ -v

- name: Run Integration Tests  
  run: pytest tests/integration/ -v

- name: Run Simulation Tests
  run: pytest tests/simulation/ -v

- name: Generate Coverage
  run: pytest tests/ --cov=app/modules --cov-report=xml
```

## ğŸ“ Soporte

Si tienes problemas con los tests:

1. **Verifica dependencias**: `pip install -r tests/requirements.txt`
2. **Ejecuta tests individuales** para aislar problemas
3. **Revisa fixtures** en `conftest.py`
4. **Consulta la estrategia completa** en `ESTRATEGIA_TESTING_APE.md`